diff --git a/utils/common_utils.py b/utils/common_utils.py
index 9681ecb..ffcbc22 100644
--- a/utils/common_utils.py
+++ b/utils/common_utils.py
@@ -115,22 +115,23 @@ def get_image(path, imsize=-1):
 
 
 
-def fill_noise(x, noise_type):
+def fill_noise(x, noise_type, generator = None):
     """Fills tensor `x` with noise of type `noise_type`."""
     if noise_type == 'u':
-        x.uniform_()
+        x.uniform_(generator = generator)
     elif noise_type == 'n':
-        x.normal_() 
+        x.normal_(generator = generator)
     else:
         assert False
 
-def get_noise(input_depth, method, spatial_size, noise_type='u', var=1./10):
+def get_noise(input_depth, method, spatial_size, generator = None, noise_type='u', var=1./10):
     """Returns a pytorch.Tensor of size (1 x `input_depth` x `spatial_size[0]` x `spatial_size[1]`) 
     initialized in a specific way.
     Args:
         input_depth: number of channels in the tensor
         method: `noise` for fillting tensor with noise; `meshgrid` for np.meshgrid
         spatial_size: spatial size of the tensor to initialize
+        generator: random generator to ensure reproducible results
         noise_type: 'u' for uniform; 'n' for normal
         var: a factor, a noise will be multiplicated by. Basically it is standard deviation scaler. 
     """
@@ -140,7 +141,7 @@ def get_noise(input_depth, method, spatial_size, noise_type='u', var=1./10):
         shape = [1, input_depth, spatial_size[0], spatial_size[1]]
         net_input = torch.zeros(shape)
         
-        fill_noise(net_input, noise_type)
+        fill_noise(net_input, noise_type, generator)
         net_input *= var            
     elif method == 'meshgrid': 
         assert input_depth == 2
@@ -195,7 +196,8 @@ def torch_to_np(img_var):
     return img_var.detach().cpu().numpy()[0]
 
 
-def optimize(optimizer_type, parameters, closure, LR, num_iter):
+def optimize(optimizer_type, parameters_optimizer, closure, fm_image, parameters_training,
+             current_net_status):
     """Runs optimization loop.
 
     Args:
@@ -207,26 +209,33 @@ def optimize(optimizer_type, parameters, closure, LR, num_iter):
     """
     if optimizer_type == 'LBFGS':
         # Do several steps with adam first
-        optimizer = torch.optim.Adam(parameters, lr=0.001)
+        optimizer = torch.optim.Adam(parameters_optimizer, lr=parameters_training['lr'])
         for j in range(100):
             optimizer.zero_grad()
-            closure()
+            closure(fm_image, parameters_training, current_net_status, j)
             optimizer.step()
 
-        print('Starting optimization with LBFGS')        
+        if parameters_training["verbosity"] > 0:
+            print('Starting optimization with LBFGS')
         def closure2():
             optimizer.zero_grad()
-            return closure()
-        optimizer = torch.optim.LBFGS(parameters, max_iter=num_iter, lr=LR, tolerance_grad=-1, tolerance_change=-1)
+            return closure(fm_image, parameters_training, current_net_status)
+        optimizer = torch.optim.LBFGS(parameters_optimizer,
+                                      max_iter=parameters_training['num_iter'],
+                                      lr=parameters_training['lr'],
+                                      tolerance_grad=-1,
+                                      tolerance_change=-1)
         optimizer.step(closure2)
 
     elif optimizer_type == 'adam':
-        print('Starting optimization with ADAM')
-        optimizer = torch.optim.Adam(parameters, lr=LR)
-        
-        for j in range(num_iter):
+        if parameters_training["verbosity"] > 0:
+            print('Starting optimization with ADAM')
+        optimizer = torch.optim.Adam(parameters_optimizer, lr=parameters_training['lr'])
+
+        for j in range(parameters_training['num_iter']):
             optimizer.zero_grad()
-            closure()
+            closure(fm_image, parameters_training, current_net_status, j)
             optimizer.step()
     else:
-        assert False
\ No newline at end of file
+        assert False
+
